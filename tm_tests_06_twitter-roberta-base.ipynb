{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "gTbJufUSzhr4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "78d733ce",
    "outputId": "6380579c-15cf-45c2-f1a3-d91c045dfc53"
   },
   "outputs": [],
   "source": [
    "#!pip install numpy<2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NiROaCEvuxpo"
   },
   "source": [
    "Import and Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EKPrbv6Ht2Hj",
    "outputId": "44f8d893-36d6-4170-9a6b-29ec87d986e1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in ./.venv/lib/python3.13/site-packages (4.52.4)\n",
      "Requirement already satisfied: datasets in ./.venv/lib/python3.13/site-packages (3.6.0)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.13/site-packages (1.6.1)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.13/site-packages (2.2.3)\n",
      "Requirement already satisfied: nltk in ./.venv/lib/python3.13/site-packages (3.9.1)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.13/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in ./.venv/lib/python3.13/site-packages (from transformers) (0.32.3)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.13/site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.13/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.13/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.13/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.13/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.venv/lib/python3.13/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.venv/lib/python3.13/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./.venv/lib/python3.13/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in ./.venv/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./.venv/lib/python3.13/site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./.venv/lib/python3.13/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: xxhash in ./.venv/lib/python3.13/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in ./.venv/lib/python3.13/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in ./.venv/lib/python3.13/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.6)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: click in ./.venv/lib/python3.13/site-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
      "Requirement already satisfied: idna>=2.0 in ./.venv/lib/python3.13/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.13/site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.13/site-packages (from requests->transformers) (2025.4.26)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets scikit-learn pandas nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "krppIXx3u0fO"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "import re\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_8Dn3D2duw-R"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J4PkR5kAt-Xd"
   },
   "source": [
    "Load Pretrained Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pEP9BZxyt5mQ",
    "outputId": "470ac6b1-aad6-45bc-e671-e9c83285241a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-2021-124m and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"cardiffnlp/twitter-roberta-base-2021-124m\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQ5gbWKSvImO"
   },
   "source": [
    "Load the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "jlYsxnOjvEXO",
    "outputId": "1eac19df-b048-44f2-b1ae-8c8844253c3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (9543, 2)\n",
      "\n",
      "Training data columns: ['text', 'label']\n",
      "\n",
      "First 5 rows of training data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$BYND - JPMorgan reels in expectations on Beyo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$CCL $RCL - Nomura points to bookings weakness...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$CX - Cemex cut at Credit Suisse, J.P. Morgan ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>$ESS: BTIG Research cuts to Neutral https://t....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$FNKO - Funko slides after Piper Jaffray PT cu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  $BYND - JPMorgan reels in expectations on Beyo...      0\n",
       "1  $CCL $RCL - Nomura points to bookings weakness...      0\n",
       "2  $CX - Cemex cut at Credit Suisse, J.P. Morgan ...      0\n",
       "3  $ESS: BTIG Research cuts to Neutral https://t....      0\n",
       "4  $FNKO - Funko slides after Piper Jaffray PT cu...      0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Load train data\n",
    "train_path = \"/content/drive/MyDrive/Project Data/train.csv\"\n",
    "#train_path = \"Project Data-20250507/train.csv\"\n",
    "train_df = pd.read_csv(train_path)\n",
    "\n",
    "# train_df = pd.read_csv(\"Project Data/train.csv\")\n",
    "# test_df = pd.read_csv(\"Project Data/test.csv\")\n",
    "\n",
    "# View shape and features\n",
    "print(\"Training data shape:\", train_df.shape)\n",
    "print(\"\\nTraining data columns:\", train_df.columns.tolist())\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nFirst 5 rows of training data:\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "jURA2_70vXeq"
   },
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "#test_df = pd.read_csv(\"/content/drive/MyDrive/Project Data/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VB8hihe-uBJ2"
   },
   "source": [
    "Use the preprocessing suggested by Cardiff NLP (which is optimized for tweets):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "XoOe24KavUps"
   },
   "outputs": [],
   "source": [
    "# Preprocessing tweets\n",
    "def preprocess_tweet(tweet):\n",
    "    tweet = re.sub(r'http\\S+', '', tweet)  # remove links\n",
    "    tweet = re.sub(r'@\\w+', '@user', tweet)  # anonymize mentions\n",
    "    tweet = re.sub(r'#', '', tweet)  # remove hashtag symbol\n",
    "    return tweet.strip()\n",
    "\n",
    "train_df['text'] = train_df['text'].apply(preprocess_tweet)\n",
    "test_df['text'] = test_df['text'].apply(preprocess_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 201
    },
    "id": "Mmf3XAjVvxNf",
    "outputId": "e1dcf11c-2ce7-4537-c455-5d559503229c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$BYND - JPMorgan reels in expectations on Beyo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$CCL $RCL - Nomura points to bookings weakness...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$CX - Cemex cut at Credit Suisse, J.P. Morgan ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>$ESS: BTIG Research cuts to Neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$FNKO - Funko slides after Piper Jaffray PT cut</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  $BYND - JPMorgan reels in expectations on Beyo...      0\n",
       "1  $CCL $RCL - Nomura points to bookings weakness...      0\n",
       "2  $CX - Cemex cut at Credit Suisse, J.P. Morgan ...      0\n",
       "3                $ESS: BTIG Research cuts to Neutral      0\n",
       "4    $FNKO - Funko slides after Piper Jaffray PT cut      0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wgl6r-AYvoMH"
   },
   "source": [
    "# Tokenize and and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g1xb8KAavuPd",
    "outputId": "304e1aba-1356-45ed-fd2a-a8fdcfeb7fe5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-2021-124m and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Tokenizer and Model\n",
    "model_name = \"cardiffnlp/twitter-roberta-base-2021-124m\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "8iWFKVmSv4ts"
   },
   "outputs": [],
   "source": [
    "# Prepare dataset for HuggingFace\n",
    "train_ds = Dataset.from_pandas(train_df)\n",
    "train_ds = train_ds.train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ezk1iQSJv6qt"
   },
   "source": [
    "Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 405,
     "referenced_widgets": [
      "14e1158805ee4555b42232f8a726c9d2",
      "8a39197fd3ff46aeb3da06ce9a2e6527",
      "d11cbce319364b35980da5c26ba95dd5",
      "78ffd7c6ea764cd99a5f93585de3940f",
      "203476d41ca843f8a5735acd935aafdf",
      "68359dde11af40a5bf6edd5b9a6624c1",
      "f39c0be932834b679883730fc48f7de2",
      "302e57e296c04b21a7fbcbb62fa6cba9",
      "71182edb85384afc9f72a233ea23e285",
      "f8d1114632bb46ae8d80aaa6de3f9bf1",
      "8837a273f68f4a339bbb8ee4290eb624"
     ]
    },
    "id": "kWNqiDSlv78u",
    "outputId": "8c2836a6-1613-4f83-ba0b-bb826fc7b5cf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 8588/8588 [00:00<00:00, 35056.66 examples/s]\n",
      "Map: 100%|██████████| 955/955 [00:00<00:00, 32088.89 examples/s]\n",
      "Map: 100%|██████████| 2388/2388 [00:00<00:00, 41743.93 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "train_ds = train_ds.map(tokenize_function, batched=True)\n",
    "train_ds = train_ds.rename_column(\"label\", \"labels\")\n",
    "train_ds.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "\n",
    "# Convert test_df to Hugging Face Dataset\n",
    "test_ds = Dataset.from_pandas(test_df)\n",
    "\n",
    "# Tokenize the test dataset\n",
    "test_ds = test_ds.map(tokenize_function, batched=True)\n",
    "\n",
    "# Format the test dataset for PyTorch\n",
    "# The test dataset does not have a 'label' column, so we don't rename it\n",
    "# and we don't include 'labels' when setting the format for the test set.\n",
    "test_ds.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "auMLpvMz3NTB"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "gJOhFB553auZ"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = logits.argmax(-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1\": f1_score(labels, preds, average=\"macro\"),\n",
    "        \"precision\": precision_score(labels, preds, average=\"macro\"),\n",
    "        \"recall\": recall_score(labels, preds, average=\"macro\"),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dB9yPK3-wD-0"
   },
   "source": [
    "Prepare Model and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ivmKX6R_wAHE"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "# TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results/twitter_roberta\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8, # with batch = 16 I got 93 for neutral f1 score\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs/twitter_roberta\",\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"no\",\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds[\"train\"],\n",
    "    eval_dataset=train_ds[\"test\"]  # Using the test split from train_ds for evaluation\n",
    "    #eval_dataset=test_ds[\"text\"]   #this might be wrong wtf\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "pbiesRtrwCkp"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joshuawehr/Library/Mobile Documents/com~apple~CloudDocs/NOVA IMS/2n Semester/Text Mining/textmining/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3222' max='3222' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3222/3222 14:03, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.338400</td>\n",
       "      <td>0.423230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.391800</td>\n",
       "      <td>0.466927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.222400</td>\n",
       "      <td>0.588254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3222, training_loss=0.34006300511449683, metrics={'train_runtime': 843.7646, 'train_samples_per_second': 30.535, 'train_steps_per_second': 3.819, 'total_flos': 1694713523586048.0, 'train_loss': 0.34006300511449683, 'epoch': 3.0})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CSPYPgVowTjn"
   },
   "source": [
    "Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "Ii8JJ2yVwWSe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Bearish       0.77      0.77      0.77       136\n",
      "     Bullish       0.83      0.86      0.84       197\n",
      "     Neutral       0.92      0.91      0.92       622\n",
      "\n",
      "    accuracy                           0.88       955\n",
      "   macro avg       0.84      0.85      0.84       955\n",
      "weighted avg       0.88      0.88      0.88       955\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "predictions = trainer.predict(train_ds[\"test\"])\n",
    "preds = torch.argmax(torch.tensor(predictions.predictions), axis=1)\n",
    "print(classification_report(predictions.label_ids, preds, target_names=[\"Bearish\", \"Bullish\", \"Neutral\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "# predictions = trainer.predict(test_ds)\n",
    "# preds = torch.argmax(torch.tensor(predictions.predictions), axis=1)\n",
    "# print(classification_report(predictions.label_ids, preds, target_names=[\"Bearish\", \"Bullish\", \"Neutral\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joshuawehr/Library/Mobile Documents/com~apple~CloudDocs/NOVA IMS/2n Semester/Text Mining/textmining/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Evaluation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Bearish       0.77      0.77      0.77       136\n",
      "     Bullish       0.83      0.86      0.84       197\n",
      "     Neutral       0.92      0.91      0.92       622\n",
      "\n",
      "    accuracy                           0.88       955\n",
      "   macro avg       0.84      0.85      0.84       955\n",
      "weighted avg       0.88      0.88      0.88       955\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Final Evaluation on validation set\n",
    "eval_result = trainer.predict(train_ds[\"test\"])\n",
    "y_true = eval_result.label_ids\n",
    "y_pred = np.argmax(eval_result.predictions, axis=1)\n",
    "\n",
    "print(\"Validation Set Evaluation Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=[\"Bearish\", \"Bullish\", \"Neutral\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fd472b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Prediction Distribution:\n",
      "Label 0: 371 samples\n",
      "Label 1: 498 samples\n",
      "Label 2: 1519 samples\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Predict on test set\n",
    "tokenized_test = tokenizer(list(test_df['text']), truncation=True, padding=True, max_length=128, return_tensors='pt')\n",
    "\n",
    "# Move tensors to correct device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "tokenized_test = {k: v.to(device) for k, v in tokenized_test.items()}\n",
    "\n",
    "# Inference\n",
    "with torch.no_grad():\n",
    "    outputs = model(**tokenized_test)\n",
    "    predictions = torch.argmax(outputs.logits, axis=1)\n",
    "\n",
    "# Show prediction distribution\n",
    "unique, counts = np.unique(predictions.cpu().numpy(), return_counts=True)\n",
    "print(\"Test Set Prediction Distribution:\")\n",
    "for label, count in zip(unique, counts):\n",
    "    print(f\"Label {label}: {count} samples\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "14e1158805ee4555b42232f8a726c9d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8a39197fd3ff46aeb3da06ce9a2e6527",
       "IPY_MODEL_d11cbce319364b35980da5c26ba95dd5",
       "IPY_MODEL_78ffd7c6ea764cd99a5f93585de3940f"
      ],
      "layout": "IPY_MODEL_203476d41ca843f8a5735acd935aafdf"
     }
    },
    "203476d41ca843f8a5735acd935aafdf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "302e57e296c04b21a7fbcbb62fa6cba9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "68359dde11af40a5bf6edd5b9a6624c1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "71182edb85384afc9f72a233ea23e285": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "78ffd7c6ea764cd99a5f93585de3940f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f8d1114632bb46ae8d80aaa6de3f9bf1",
      "placeholder": "​",
      "style": "IPY_MODEL_8837a273f68f4a339bbb8ee4290eb624",
      "value": " 0/8588 [00:00&lt;?, ? examples/s]"
     }
    },
    "8837a273f68f4a339bbb8ee4290eb624": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8a39197fd3ff46aeb3da06ce9a2e6527": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_68359dde11af40a5bf6edd5b9a6624c1",
      "placeholder": "​",
      "style": "IPY_MODEL_f39c0be932834b679883730fc48f7de2",
      "value": "Map:   0%"
     }
    },
    "d11cbce319364b35980da5c26ba95dd5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_302e57e296c04b21a7fbcbb62fa6cba9",
      "max": 8588,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_71182edb85384afc9f72a233ea23e285",
      "value": 0
     }
    },
    "f39c0be932834b679883730fc48f7de2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f8d1114632bb46ae8d80aaa6de3f9bf1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
